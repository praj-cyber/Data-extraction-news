{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038e86bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine, Column, String, Text, DateTime, Integer\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Article(Base):\n",
    "    __tablename__ = 'articles'\n",
    "    id = Column(String, primary_key=True)\n",
    "    title = Column(String)\n",
    "    content = Column(Text)\n",
    "    pub_date = Column(DateTime)\n",
    "    source_url = Column(String)\n",
    "    category = Column(String)\n",
    "\n",
    "engine = create_engine('postgresql://user:password@localhost/news_db')\n",
    "Base.metadata.create_all(engine)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "feeds = [\n",
    "    'http://rss.cnn.com/rss/cnn_topstories.rss',\n",
    "    'http://qz.com/feed',\n",
    "    'http://feeds.foxnews.com/foxnews/politics',\n",
    "    'http://feeds.reuters.com/reuters/businessNews',\n",
    "    'http://feeds.feedburner.com/NewshourWorld',\n",
    "    'https://feeds.bbci.co.uk/news/world/asia/india/rss.xml'\n",
    "]\n",
    "\n",
    "def parse_feed(feed_url):\n",
    "    feed = feedparser.parse(feed_url)\n",
    "    for entry in feed.entries:\n",
    "        article = Article(\n",
    "            id=entry.id,\n",
    "            title=entry.title,\n",
    "            content=entry.description,\n",
    "            pub_date=datetime(*entry.published_parsed[:6]),\n",
    "            source_url=entry.link\n",
    "        )\n",
    "        session.merge(article)\n",
    "    session.commit()\n",
    "\n",
    "for feed in feeds:\n",
    "    parse_feed(feed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de1b40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from celery import Celery\n",
    "from sqlalchemy import update\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "app = Celery('tasks', broker='pyamqp://guest@localhost//')\n",
    "\n",
    "@app.task\n",
    "def process_article(article_id):\n",
    "    article = session.query(Article).get(article_id)\n",
    "    # Simple keyword-based classification\n",
    "    if 'terrorism' in article.content or 'protest' in article.content:\n",
    "        category = 'Terrorism / protest / political unrest / riot'\n",
    "    elif 'positive' in article.content or 'uplifting' in article.content:\n",
    "        category = 'Positive/Uplifting'\n",
    "    elif 'earthquake' in article.content or 'flood' in article.content:\n",
    "        category = 'Natural Disasters'\n",
    "    else:\n",
    "        category = 'Others'\n",
    "\n",
    "    stmt = update(Article).where(Article.id == article_id).values(category=category)\n",
    "    session.execute(stmt)\n",
    "    session.commit()\n",
    "\n",
    "for article in session.query(Article).all():\n",
    "    process_article.delay(article.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ae8462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')\n",
    "\n",
    "def parse_feed(feed_url):\n",
    "    try:\n",
    "        feed = feedparser.parse(feed_url)\n",
    "        for entry in feed.entries:\n",
    "            article = Article(\n",
    "                id=entry.id,\n",
    "                title=entry.title,\n",
    "                content=entry.description,\n",
    "                pub_date=datetime(*entry.published_parsed[:6]),\n",
    "                source_url=entry.link\n",
    "            )\n",
    "            session.merge(article)\n",
    "        session.commit()\n",
    "        logging.info(f'Successfully parsed and stored articles from {feed_url}')\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error parsing feed {feed_url}: {e}')\n",
    "\n",
    "for feed in feeds:\n",
    "    parse_feed(feed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
